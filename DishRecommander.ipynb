{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORDERS_PATH = '../finals/full_order_all_columns.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "class FilesManagement:\n",
    "    \"\"\"this class provide operations for files management.\"\"\" \n",
    "    def read_file(self,**kwargs):\n",
    "        \"\"\"read_file(**kwargs)--->reading from given file path, works with pandas and pickle library.\n",
    "        **kwargs parameters: \n",
    "        file_path: is the path of file, required.\n",
    "        columns_to_rename: path of columns to rename file or dict, optional.\n",
    "        columns_to_drop: path of columns to drop names file or list, optional, dropping done after rename.\"\"\"\n",
    "        try:\n",
    "            if str(kwargs['file_path']).endswith('.csv'):\n",
    "                self.df = pd.read_csv(kwargs['file_path'])\n",
    "            elif str(kwargs['file_path']).endswith('.xslx'):\n",
    "                self.df = pd.read_csv(kwargs['file_path'])\n",
    "            else:\n",
    "                print('not supported file format.')\n",
    "                raise ValueError()\n",
    "            self.df = self.__rename_columns__(kwargs.get('columns_to_rename',None))\n",
    "            self.df = self.__drop_columns__(kwargs.get('columns_to_drop',None))\n",
    "            return self.df\n",
    "        except Exception as ex:\n",
    "            print('Some Error in reading file:',ex)\n",
    "            raise ex\n",
    "        return self.df\n",
    "    \n",
    "    def __rename_columns__(self,columns):\n",
    "        try:\n",
    "            if isinstance(columns,dict):\n",
    "                return self.df.rename(columns= columns)\n",
    "            elif isinstance(columns,str):\n",
    "                \n",
    "                with open(columns,'rb') as file:\n",
    "                    columns_to_rename= pickle.load(file)\n",
    "                return self.df.rename(columns= columns_to_rename)\n",
    "            else:\n",
    "                return self.df      \n",
    "        except Exception as ex:\n",
    "            print('Some Error in FilesManagement->rename_columns',ex)\n",
    "            raise ex\n",
    "            return self.df  \n",
    "            \n",
    "    def __drop_columns__(self,columns):\n",
    "        try:\n",
    "            if isinstance(columns,list):\n",
    "                return self.df.drop(columns= columns) \n",
    "            elif isinstance(columns,str):\n",
    "                with open(columns,'rb') as file:\n",
    "                    columns_to_drop = pickle.load(file)\n",
    "                return self.df.drop(columns= columns_to_drop)\n",
    "            else:\n",
    "                return self.df\n",
    "        except Exception as ex:\n",
    "            print('Some Error in FilesManagement->drop_columns',ex)\n",
    "            return self.df  \n",
    "        \n",
    "class BillsAccumelator(FilesManagement):\n",
    "    \"\"\"this class provide us to accumelate bills from orders.\"\"\"\n",
    "    def __init__(self,**kwargs):\n",
    "        \"\"\"init(self,**kwargs)---> \n",
    "        **kwargs parameters:\n",
    "        orders_path: path of orders file,required.\n",
    "        the orders file must have columns:[bill_id,dish_id]  \"\"\"\n",
    "        try:\n",
    "            self.orders = self.read_file(file_path=kwargs['orders_path'])\n",
    "            self.groups = self.orders.groupby('bill_id')\n",
    "            self.bills = {}\n",
    "        except Exception as ex:\n",
    "            print('Some Error in BillsAccumelator->init:',ex)\n",
    "    def accumelate_bills(self,**kwargs):\n",
    "        \"\"\"accumelate_bills(**kwargs)---> this function improve us to accumelate bills from orders.\n",
    "        **kwargs parameters: no parameters\"\"\"\n",
    "        def get_bill_items(bill,bills):\n",
    "            try:\n",
    "                bills[bill.name].append(bill['dish_id'].values.tolist())\n",
    "            except:\n",
    "                bills[bill.name]= bill['dish_id'].values.tolist()\n",
    "                \n",
    "        self.groups.apply(get_bill_items,bills=self.bills)\n",
    "        bills_ = pd.Series(self.bills)\n",
    "        self.bills = pd.DataFrame(bills_,columns=['dishes'])\n",
    "#         self.bills = self.bills.reset_index().rename(columns={'index':'bill_id'})\n",
    "        return self.bills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "class ObjectsManagement:\n",
    "    \"\"\"read and write objects on given path.\n",
    "    works by pickel.\"\"\"\n",
    "    def read_object(path):\n",
    "        try:\n",
    "            with open(path,'rb') as file:\n",
    "                object_ = pickle.load(file)\n",
    "        except Exception as ex:\n",
    "            print('Some error in reading from file:',path)\n",
    "            raise ex\n",
    "        return object_\n",
    "    \n",
    "    def write_object(path,obj):\n",
    "        try:\n",
    "            with open(path,'wb') as file:\n",
    "                pickle.dump(obj,file)\n",
    "        except Exception as ex:\n",
    "            print('Some error in writing to file:',path)\n",
    "            raise ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-317-9e1622b385b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.mlxtend.frequent_patterns import association_rules\n",
    "class Recommander:\n",
    "    \"\"\"Interface to define rocommanders methods.\"\"\"\n",
    "    def prepare_data(self,**kwargs):\n",
    "        \"\"\"Transforming Data in way that models accept\"\"\"\n",
    "        pass\n",
    "    def extract_patterns(self,**kwargs):\n",
    "        \"\"\"get patterns from TransactionData\"\"\"\n",
    "        pass\n",
    "    def build_recommander_model(self, **kwargs):\n",
    "        \"\"\"define the model that recommandation system will apply.\"\"\"\n",
    "        pass\n",
    "    def make_recommandation(self,**kwargs):\n",
    "        \"\"\"make recommandation on some item.\"\"\"\n",
    "        pass\n",
    "\n",
    "class EvaluationMethods:\n",
    "    pass\n",
    "\n",
    "class RulesEvaluation(EvaluationMethods):\n",
    "    \"\"\"\"\"\"\n",
    "    def jacard_evalution(self,rule,itemset):\n",
    "        \"\"\"jacard_evalution(rule,itemset)--->\"\"\"\n",
    "        try:\n",
    "            antencedent = rule['antecedents']\n",
    "            consequent = rule['consequents']\n",
    "            support_ant = itemset.support[itemset['itemsets'].str.contains(antencedent)].sum()\n",
    "            support_con = itemset.support[itemset['itemsets'].str.contains(consequent)].sum()\n",
    "            support_intersection = itemset.support[itemset['itemsets'].str.contains(antencedent) & itemset['itemsets'].str.contains(consequent) ].sum()\n",
    "            eq = float(support_ant + support_con - support_intersection)\n",
    "            if eq == 0:\n",
    "                eq = support_intersection\n",
    "                \n",
    "            jaccard = float(support_intersection)/ eq\n",
    "            ir = np.abs(support_ant - support_con) / eq\n",
    "            return jaccard, ir \n",
    "        \n",
    "        except Exception as ex:\n",
    "            print('Some Error in RulesEvaluation->jacard_evalution',ex)\n",
    "            raise ex\n",
    "    \n",
    "class AssosiationRulesRecommander(Recommander):\n",
    "    \"\"\"Recommandation System Class Based On AssusiationRules as model,\n",
    "    and FbGrowth as DataPrepare Algorithm.\"\"\"\n",
    "    def __init__(self,**kwargs):\n",
    "        try:\n",
    "            self.items = kwargs['items']\n",
    "            self.evaluation_columns = []\n",
    "        except Exception as ex:\n",
    "            print('Some Error in AssosiationRulesRecommander->init',ex)\n",
    "            raise ex\n",
    "    def prepare_data(self,**kwargs):\n",
    "        \"\"\"prepare_data(**kwargs)---> Transforming Data in way that models accept.\n",
    "        **kwargs parameters:\n",
    "        data: the data of Transactions.\"\"\"\n",
    "        try:\n",
    "            te = TransactionEncoder()\n",
    "            transformed_data = te.fit_transform(self.items)\n",
    "            self.df = pd.DataFrame(transformed_data, columns=te.columns_)\n",
    "        except Exception as ex:\n",
    "            print('Some Error in AssosiationRulesRecommander->prepare_data',ex)\n",
    "            raise ex\n",
    "        \n",
    "    def extract_patterns(self,**kwargs):\n",
    "        \"\"\"extract_patterns(**kwargs)---> \n",
    "        **kwargs parameters:\n",
    "        min_support: the minimum support of frequent item to consider as pattern. \n",
    "        max_len:\"\"\"\n",
    "        try:\n",
    "            def frozenset_to_string(x):\n",
    "                return ','.join(str(i) for i in x)    \n",
    "            self.df = fpgrowth(self.df, min_support=0.0001,max_len=4)\n",
    "            self.df_copy = self.df.copy()\n",
    "            self.df_copy['itemsets'] = self.df_copy['itemsets'].apply(frozenset_to_string)\n",
    "        except Exception as ex:\n",
    "            print('Some Error in AssosiationRulesRecommander->build_recommander_model',ex)\n",
    "            raise ex\n",
    "\n",
    "    def build_recommander_model(self, **kwargs):\n",
    "        \"\"\"\"\"\"\n",
    "        try:\n",
    "            def frozenset_to_string(x):\n",
    "                return ','.join(str(i) for i in x)\n",
    "            \n",
    "            self.rules = association_rules(self.df, metric=\"lift\", min_threshold=kwargs.get('min_threshold',1000))\n",
    "            try:\n",
    "                self.rules['antecedents'] = self.rules.antecedents.apply(frozenset_to_string)\n",
    "                self.rules['consequents'] = self.rules.consequents.apply(frozenset_to_string)\n",
    "            except Exception as ex:\n",
    "                print('Some Error in AssosiationRulesRecommander->transform frozen to string',ex)\n",
    "        except Exception as ex:\n",
    "            print('Some Error in AssosiationRulesRecommander->build_recommander_model',ex)\n",
    "            raise ex \n",
    "            \n",
    "    def evaluation(self,**kwargs):\n",
    "         try:\n",
    "            self.evaluation_columns = ['jaccard','ir']\n",
    "            evaluation_func = kwargs['evaluation_func']\n",
    "            self.rules[self.evaluation_columns] = self.rules.apply(evaluation_func,itemset=self.df_copy,axis=1,result_type=\"expand\")\n",
    "            return self.rules\n",
    "         except Exception as ex:\n",
    "            print('Some Error in AssosiationRulesRecommander->evaluation',ex)\n",
    "            raise ex  \n",
    "    def make_recommandation(self,item_id,**kwargs):\n",
    "        \"\"\"make_recommandation(item_id,**kwargs)---> make recommandations for given item id.\"\"\"\n",
    "        try:\n",
    "            reco = self.rules[['antecedents','consequents']+self.evaluation_columns][self.rules['antecedents']==item_id]\n",
    "            return reco\n",
    "        except Exception as ex:\n",
    "            print('Some Error in AssosiationRulesRecommander->make_recommandation',ex)\n",
    "            raise ex  \n",
    "        pass\n",
    "\n",
    "class DishRecommander:\n",
    "    \"\"\"this class provide us to give recommandations on the dish\"\"\"\n",
    "    def __init__(self,**kwargs):\n",
    "        \"\"\"init(**kwargs)---> \n",
    "        **kwagrs parameters: \n",
    "        recommander_path: path of trained recommander model, optional.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if kwargs.get('recommander_path') != None:\n",
    "                self.recommander = ObjectsManagement.read_object(kwargs.get('recommander_path'))\n",
    "        except Exception as ex:\n",
    "            print('Some Error in DishRecommander->init',ex)\n",
    "    def fit(self,**kwargs):\n",
    "        \"\"\"bulid reccomander and fit data.\n",
    "        fit(**kwargs)--->\n",
    "        **kwagrs parameters:\n",
    "        orders_path: path of orders file must contain bill_id,dish_id field, required.\"\"\"\n",
    "        try:\n",
    "            print('collecting bills...')\n",
    "            self.ba = BillsAccumelator(orders_path = kwargs['orders_path'])\n",
    "            self.bills = self.ba.accumelate_bills()\n",
    "            print('building recommander...')\n",
    "            self.recommander = AssosiationRulesRecommander(items=self.bills['dishes'])\n",
    "            self.recommander.prepare_data()\n",
    "            self.recommander.extract_patterns()\n",
    "            self.recommander.build_recommander_model()\n",
    "            ev = RulesEvaluation()\n",
    "            print('apply evaluation...')\n",
    "            self.recommander.evaluation(evaluation_func = ev.jacard_evalution)\n",
    "            print('done.')\n",
    "        except Exception as ex:\n",
    "            print('Some Error in DishRecommander->fit',ex) \n",
    "            \n",
    "    def predict(self,item):\n",
    "        \"\"\"give you a recommandation.\"\"\"\n",
    "        try:\n",
    "            recommanded_arr = []\n",
    "            def split_and_merge(item,arr):\n",
    "                arr += [i for i in item.split(',')]\n",
    "                \n",
    "            recommandation = self.recommander.make_recommandation(item)\n",
    "          \n",
    "            recommandation.sort_values('jaccard')['consequents'].apply(split_and_merge,arr=recommanded_arr)\n",
    "            return set(recommanded_arr)\n",
    "        except Exception as ex:\n",
    "            print('Some Error in DishRecommander->predict',ex)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dr = DishRecommander()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting bills...\n",
      "building recommander...\n",
      "apply evaluation...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "# dr.fit(orders_path = ORDERS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'11306', '11311', '11314', '11315', '11316', '11317'}"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.predict('11310')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr1 = DishRecommander(recommander_path= 'association_rules_bill_recommander_1000.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'11306', '11311', '11314', '11315', '11316', '11317'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr1.predict('11310')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
